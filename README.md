# ğŸ’»ğŸ“– hacker-laws

[![gitlocalized](https://gitlocalize.com/repo/2513/whole_project/badge.svg)](https://gitlocalize.com/repo/2513/whole_project?utm_source=badge)

CÃ¡c Äá»‹nh luáº­t, LÃ½ thuyáº¿t, NguyÃªn táº¯c vÃ  KhuÃ´n máº«u há»¯u Ã­ch cho cÃ¡c nhÃ  phÃ¡t triá»ƒn.

TÃ i liá»‡u Ä‘Æ°á»£c dá»‹ch tá»« báº£n gá»‘c cá»§a [Dave Kerr](https://github.com/dwmkerr/hacker-laws) táº¡i [Ä‘Ã¢y](https://github.com/dwmkerr/hacker-laws)

---

<!-- vim-markdown-toc GFM -->

- [ğŸ’»ğŸ“– hacker-laws](#%f0%9f%92%bb%f0%9f%93%96-hacker-laws)
  - [Giá»›i thiá»‡u](#gi%e1%bb%9bi-thi%e1%bb%87u)
  - [CÃ¡c Ä‘á»‹nh luáº­t](#c%c3%a1c-%c4%91%e1%bb%8bnh-lu%e1%ba%adt)
    - [Luáº­t Amdahl](#lu%e1%ba%adt-amdahl)
    - [LÃ½ thuyáº¿t Cá»­a sá»• vá»¡](#l%c3%bd-thuy%e1%ba%bft-c%e1%bb%ada-s%e1%bb%95-v%e1%bb%a1)
    - [Luáº­t Brooks](#lu%e1%ba%adt-brooks)
    - [Luáº­t Conway](#lu%e1%ba%adt-conway)
    - [Luáº­t Cunningham](#lu%e1%ba%adt-cunningham)
    - [Sá»‘ Dunbar](#s%e1%bb%91-dunbar)
    - [Luáº­t Gall](#lu%e1%ba%adt-gall)
    - [Luáº­t Goodhart](#lu%e1%ba%adt-goodhart)
    - [Hanlon's Razor](#hanlons-razor)
    - [Hofstadter's Law](#hofstadters-law)
    - [Hutber's Law](#hutbers-law)
    - [The Hype Cycle & Amara's Law](#the-hype-cycle--amaras-law)
    - [Hyrum's Law (The Law of Implicit Interfaces)](#hyrums-law-the-law-of-implicit-interfaces)
    - [Kernighan's Law](#kernighans-law)
    - [Metcalfe's Law](#metcalfes-law)
    - [Moore's Law](#moores-law)
    - [Murphy's Law / Sod's Law](#murphys-law--sods-law)
    - [Occam's Razor](#occams-razor)
    - [Parkinson's Law](#parkinsons-law)
    - [Premature Optimization Effect](#premature-optimization-effect)
    - [Putt's Law](#putts-law)
    - [Reed's Law](#reeds-law)
    - [The Law of Conservation of Complexity (Tesler's Law)](#the-law-of-conservation-of-complexity-teslers-law)
    - [The Law of Leaky Abstractions](#the-law-of-leaky-abstractions)
    - [The Law of Triviality](#the-law-of-triviality)
    - [The Unix Philosophy](#the-unix-philosophy)
    - [MÃ´ hÃ¬nh Spotify](#m%c3%b4-h%c3%acnh-spotify)
    - [Wadler's Law](#wadlers-law)
    - [Wheaton's Law](#wheatons-law)
  - [Principles](#principles)
    - [The Dilbert Principle](#the-dilbert-principle)
    - [The Pareto Principle (The 80/20 Rule)](#the-pareto-principle-the-8020-rule)
    - [The Peter Principle](#the-peter-principle)
    - [The Robustness Principle (Postel's Law)](#the-robustness-principle-postels-law)
    - [SOLID](#solid)
    - [The Single Responsibility Principle](#the-single-responsibility-principle)
    - [The Open/Closed Principle](#the-openclosed-principle)
    - [The Liskov Substitution Principle](#the-liskov-substitution-principle)
    - [The Interface Segregation Principle](#the-interface-segregation-principle)
    - [The Dependency Inversion Principle](#the-dependency-inversion-principle)
    - [NguyÃªn táº¯c DRY](#nguy%c3%aan-t%e1%ba%afc-dry)
    - [NguyÃªn táº¯c KISS](#nguy%c3%aan-t%e1%ba%afc-kiss)
    - [YAGNI](#yagni)
    - [The Fallacies of Distributed Computing](#the-fallacies-of-distributed-computing)
  - [Reading List](#reading-list)
  - [Contributing](#contributing)
  - [TODO](#todo)

<!-- vim-markdown-toc -->

## Giá»›i thiá»‡u

Khi nÃ³i Ä‘áº¿n phÃ¡t triá»ƒn hay khoa há»c mÃ¡y tÃ­nh, cÃ³ ráº¥t nhiá»u Ä‘á»‹nh luáº­t, lÃ½ thuyáº¿t, nguyÃªn táº¯c hay lÃ  khuÃ´n máº«u Ä‘Æ°á»£c Ä‘em ra tháº£o luáº­n vÃ  Ã¡p dá»¥ng. TÃ i liá»‡u nÃ y Ä‘Æ°a ra má»™t gÃ³c nhÃ¬n tá»•ng quan vá» má»™t sá»‘ luáº­t phá»• biáº¿n nháº¥t.

â—: TÃ i liá»‡u nÃ y bao gá»“m pháº§n giáº£i thÃ­ch cá»§a má»™t sá»‘ Ä‘á»‹nh luáº­t, nguyÃªn táº¯c vÃ  khuÃ´n máº«u, nhÆ°ng khÃ´ng kháº³ng Ä‘á»‹nh sá»± á»§ng há»™ cho báº¥t kÃ¬ cÃ¡i nÃ o. Viá»‡c chÃºng cÃ³ nÃªn Ä‘Æ°á»£c Ã¡p dá»¥ng hay khÃ´ng sáº½ luÃ´n lÃ  má»™t váº¥n Ä‘á» cáº§n tranh luáº­n, vÃ  Ä‘iá»u Ä‘Ã³ phá»¥ thuá»™c ráº¥t lá»›n vÃ o nhá»¯ng gÃ¬ báº¡n Ä‘ang lÃ m.

## CÃ¡c Ä‘á»‹nh luáº­t

### Luáº­t Amdahl

[Luáº­t Amdahl xem táº¡i Wikipedia](https://vi.wikipedia.org/wiki/Lu%E1%BA%ADt_Amdahl)

> Luáº­t Amdahl lÃ  má»™t cÃ´ng thá»©c thá»ƒ hiá»‡n kháº£ nÄƒng tÄƒng tá»‘c mÃ  má»™t tÃ¡c vá»¥ tÃ­nh toÃ¡n cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c báº±ng cÃ¡ch tÄƒng lÆ°á»£ng tÃ i nguyÃªn cá»§a má»™t há»‡ thá»‘ng. NÃ³ thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng trong tÃ­nh toÃ¡n song song vÃ  cÃ³ kháº£ nÄƒng dá»± Ä‘oÃ¡n lá»£i Ã­ch thá»±c táº¿ cá»§a viá»‡c tÄƒng sá»‘ lÆ°á»£ng bá»™ xá»­ lÃ½, Ä‘iá»u bá»‹ giá»›i háº¡n bá»Ÿi tÃ­nh song song cá»§a chÆ°Æ¡ng trÃ¬nh.

Láº¥y vÃ­ dá»¥, náº¿u má»™t chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c táº¡o nÃªn bá»Ÿi hai pháº§n, trong Ä‘Ã³ pháº§n A chá»‰ cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c thi bá»Ÿi má»™t bá»™ xá»­ lÃ½ Ä‘Æ¡n láº» cÃ²n pháº§n B cÃ³ thá»ƒ Ä‘Æ°á»£c song song hoÃ¡ thÃ¬ chÃºng ta sáº½ tháº¥y viá»‡c thÃªm nhiá»u bá»™ xá»­ lÃ½ cho há»‡ thá»‘ng thá»±c thi chÆ°Æ¡ng trÃ¬nh Ä‘Ã³ chá»‰ mang láº¡i nhá»¯ng lá»£i Ã­ch háº¡n cháº¿. NÃ³ cÃ³ kháº£ nÄƒng cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ tá»‘c Ä‘á»™ cá»§a pháº§n B, nhÆ°ng tá»‘c Ä‘á»™ cá»§a pháº§n A sáº½ khÃ´ng thay Ä‘á»•i.

Biá»ƒu Ä‘á»“ dÆ°á»›i Ä‘Ã¢y minh hoáº¡ cho kháº£ nÄƒng cáº£i thiá»‡n tá»‘c Ä‘á»™ cá»§a viá»‡c thÃªm bá»™ xá»­ lÃ½ cho há»‡ thá»‘ng thá»±c thi chÆ°Æ¡ng trÃ¬nh song song.

<img width="480px" alt="Diagram: Amdahl's Law" src="./images/amdahls_law.png" />

*(Nguá»“n áº£nh: Bá»Ÿi Daniels220 tá»« Wikipedia Tiáº¿ng Anh, Creative Commons Attribution-Share Alike 3.0 Unported, https://en.wikipedia.org/wiki/File:AmdahlsLaw.svg)*

NhÆ° chÃºng ta cÃ³ thá»ƒ tháº¥y, má»™t chÆ°Æ¡ng trÃ¬nh Ä‘Æ°á»£c song song hoÃ¡ 50% sáº½ tÄƒng tá»‘c ráº¥t háº¡n cháº¿ khi thÃªm quÃ¡ 10 Ä‘Æ¡n vá»‹ xá»­ lÃ½, trong khi Ä‘Ã³ má»™t chÆ°Æ¡ng trÃ¬nh cÃ³ thÃ nh pháº§n song song hoÃ¡ chiáº¿m 95% váº«n cho tháº¥y sá»± cáº£i thiá»‡n vá» tá»‘c Ä‘á»™ khi sá»‘ lÆ°á»£ng Ä‘Æ¡n vá»‹ xá»­ lÃ½ vÆ°á»£t quÃ¡ hÃ ng nghÃ¬n.

Khi khoáº£ng thá»i gian Ä‘Æ°á»£c nháº¯c tá»›i trong [Luáº­t Moore](#moores-law) cháº­m láº¡i, hay sá»± tÄƒng trÆ°á»Ÿng trong tá»‘c Ä‘á»™ cá»§a má»™t bá»™ xá»­ lÃ½ Ä‘Æ¡n láº» giáº£m Ä‘i, tÃ­nh song song lÃ  chÃ¬a khoÃ¡ cá»§a viá»‡c cáº£i thiá»‡n hiá»‡u nÄƒng. Láº­p trÃ¬nh Ä‘á»“ hoáº¡ (Graphics programming) lÃ  má»™t vÃ­ dá»¥ tuyá»‡t vá»i cho Ä‘iá»u nÃ y. Trong mÃ´ hÃ¬nh tÃ­nh toÃ¡n dá»±a trÃªn Shader (Shader based computing) ngÃ y nay, má»—i Ä‘iá»ƒm áº£nh hay thÃ nh pháº§n Ä‘á»u cÃ³ thá»ƒ Ä‘Æ°á»£c káº¿t xuáº¥t song song. VÃ¬ váº­y, viá»‡c sá»­ dá»¥ng nhiá»u bá»™ xá»­ lÃ½ cÃ³ thá»ƒ cáº£i thiá»‡n tá»‘c Ä‘á»™ tÃ­nh toÃ¡n má»™t cÃ¡ch Ä‘Ã¡ng ká»ƒ. ÄÃ³ lÃ  lÃ­ do vÃ¬ sao cÃ¡c card Ä‘á»“ há»a hiá»‡n nay thÆ°á»ng cÃ³ hÃ ng nghÃ¬n lÃµi xá»­ lÃ½ (GPUs hay Ä‘Æ¡n vá»‹ Shader).

Xem thÃªm:

- [Luáº­t Brooks](#brooks-law)
- [Luáº­t Moore](#moores-law)

### LÃ½ thuyáº¿t Cá»­a sá»• vá»¡

[LÃ½ thuyáº¿t Cá»­a sá»• vá»¡ xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Broken_windows_theory)

LÃ½ thuyáº¿t Cá»­a sá»• vá»¡ gá»£i Ã½ ráº±ng nhá»¯ng dáº¥u hiá»‡u pháº¡m tá»™i trá»±c quan (hay sá»± thiáº¿u quan tÃ¢m Ä‘áº¿n má»™t mÃ´i trÆ°á»ng nÃ o Ä‘Ã³) cÃ³ thá»ƒ dáº«n tá»›i nhá»¯ng hÃ nh Ä‘á»™ng pháº¡m tá»™i nghiÃªm trá»ng hÆ¡n (hay sá»± phÃ¡ huá»· mÃ´i trÆ°á»ng náº·ng ná» hÆ¡n).

LÃ½ thuyáº¿t nÃ y Ä‘Ã£ Ä‘Æ°á»£c Ã¡p dá»¥ng vÃ o phÃ¡t triá»ƒn pháº§n má»m. NÃ³ cho ráº±ng nhá»¯ng Ä‘oáº¡n mÃ£ nguá»“n kÃ©m cháº¥t lÆ°á»£ng náº¿u khÃ´ng Ä‘Æ°á»£c sá»­a chá»¯a ká»‹p thá»i, sáº½ dáº«n Ä‘áº¿n viá»‡c bá» qua (hoáº·c Ä‘Ã¡nh giÃ¡ tháº¥p) cÃ¡c ná»— lá»±c cáº£i thiá»‡n cháº¥t lÆ°á»£ng, tá»« Ä‘Ã³ dáº«n Ä‘áº¿n nhiá»u Ä‘oáº¡n mÃ£ kÃ©m cháº¥t lÆ°á»£ng hÆ¡n. Theo thá»i gian, cháº¥t lÆ°á»£ng cá»§a mÃ£ nguá»“n (vÃ  sáº£n pháº©m) sáº½ bá»‹ suy giáº£m nghiÃªm trá»ng.

Xem thÃªm (Tiáº¿ng Anh):

- [The Pragmatic Programming: Software Entropy](https://pragprog.com/the-pragmatic-programmer/extracts/software-entropy)
- [Coding Horror: The Broken Window Theory](https://blog.codinghorror.com/the-broken-window-theory/)
- [OpenSource: Joy of Programming - The Broken Window Theory](https://opensourceforu.com/2011/05/joy-of-programming-broken-window-theory/)

### Luáº­t Brooks

[Luáº­t Brooks xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Brooks%27s_law)

> Viá»‡c thÃªm ngÆ°á»i vÃ o má»™t dá»± Ã¡n phÃ¡t triá»ƒn pháº§n má»m Ä‘Ã£ cháº­m tiáº¿n Ä‘á»™ thÆ°á»ng sáº½ khiáº¿n nÃ³ cháº­m hÆ¡n.

Luáº­t nÃ y gá»£i Ã½ ráº±ng trong nhiá»u trÆ°á»ng há»£p, viá»‡c cá»‘ gáº¯ng Ä‘áº©y nhanh má»™t dá»± Ã¡n Ä‘Ã£ bá»‹ cháº­m tiáº¿n Ä‘á»™ báº±ng viá»‡c thÃªm nhiá»u ngÆ°á»i sáº½ khiáº¿n viá»‡c hoÃ n thÃ nh tháº­m chÃ­ cháº­m hÆ¡n. DÃ¹ chÃ­nh Brooks Ä‘Ã£ kháº³ng Ä‘á»‹nh ráº±ng luáº­t nÃ y Ä‘Ã£ bá»‹ Ä‘Æ¡n giáº£n hoÃ¡ quÃ¡ má»©c, nhÆ°ng luáº­n Ä‘iá»ƒm chung cá»§a nÃ³ lÃ  vá»›i thá»i gian pháº£i bá» ra cho cÃ¡c nguá»“n tÃ i nguyÃªn má»›i vÃ  gÃ¡nh náº·ng giao tiáº¿p, tá»‘c Ä‘á»™ trong ngáº¯n háº¡n sáº½ giáº£m Ä‘i. HÆ¡n ná»¯a, ráº¥t nhiá»u tÃ¡c vá»¥ cÃ³ thá»ƒ khÃ´ng chia nhá» Ä‘Æ°á»£c (hay dá»… dÃ ng phÃ¢n chia cho cÃ¡c nguá»“n lá»±c tÄƒng cÆ°á»ng), nghÄ©a lÃ  kháº£ nÄƒng tÄƒng tá»‘c nÃ³i chung cÅ©ng tháº¥p hÆ¡n.

CÃ³ má»™t cÃ¢u nÃ³i phá»• biáº¿n liÃªn quan tá»›i luáº­t Brooks: "ChÃ­n ngÆ°á»i phá»¥ ná»¯ cÅ©ng khÃ´ng thá»ƒ sinh ra má»™t Ä‘á»©a tráº» trong má»™t thÃ¡ng", hay má»™t sá»‘ loáº¡i cÃ´ng viá»‡c Ä‘Æ¡n giáº£n lÃ  khÃ´ng thá»ƒ chia nhá» hay song song hoÃ¡ Ä‘Æ°á»£c.

Luáº­t nÃ y lÃ  chá»§ Ä‘á» chÃ­nh cá»§a cuá»‘n sÃ¡ch '[The Mythical Man Month](#reading-list)'

Xem thÃªm:

- [Reading List: The Mythical Man Month](#reading-list)

### Luáº­t Conway

[Luáº­t Conway xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Conway%27s_law)

Luáº­t Conway gá»£i Ã½ ráº±ng nhá»¯ng giá»›i háº¡n ká»¹ thuáº­t cá»§a má»™t há»‡ thá»‘ng sáº½ pháº£n Ã¡nh cáº¥u trÃºc cá»§a tá»• chá»©c lÃ m ra nÃ³. Luáº­t nÃ y thÆ°á»ng Ä‘Æ°á»£c Ä‘á» cáº­p khi xem xÃ©t cÃ¡c cáº£i tiáº¿n cá»§a tá»• chá»©c, ráº±ng náº¿u má»™t tá»• chá»©c Ä‘Æ°á»£c cáº¥u thÃ nh tá»« nhá»¯ng Ä‘Æ¡n vá»‹ nhá» láº», rá»i ráº¡c, pháº§n má»m mÃ  nÃ³ táº¡o ra cÅ©ng sáº½ nhÆ° váº­y. Náº¿u má»™t tá»• chá»©c Ä‘Æ°á»£c xÃ¢y dá»±ng "theo chiá»u dá»c" vÃ  Ä‘Æ°á»£c Ä‘á»‹nh hÆ°á»›ng xung quanh cÃ¡c tÃ­nh nÄƒng vÃ  dá»‹ch vá»¥, há»‡ thá»‘ng pháº§n má»m cá»§a há» cÅ©ng sáº½ pháº£n Ã¡nh Ä‘iá»u nÃ y. 

Xem thÃªm:

- [MÃ´ hÃ¬nh Spotify](#m%c3%b4-h%c3%acnh-spotify)

### Luáº­t Cunningham

[Luáº­t Cunningham xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Ward_Cunningham#Cunningham's_Law)

> CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘Ãºng trÃªn Internet khÃ´ng pháº£i lÃ  Ä‘áº·t cÃ¢u há»i, mÃ  lÃ  Ä‘Äƒng lÃªn má»™t cÃ¢u tráº£ lá»i sai.

Theo [Steven McGeady](https://en.wikipedia.org/wiki/Steven_McGeady), [Ward Cunningham](https://en.wikipedia.org/wiki/Ward_Cunningham) Ä‘Ã£ Ä‘Æ°a ra lá»i khuyÃªn nÃ y cho Ã´ng vÃ o Ä‘áº§u nhá»¯ng nÄƒm 80: "CÃ¡ch tá»‘t nháº¥t Ä‘á»ƒ tÃ¬m Ä‘Æ°á»£c cÃ¢u tráº£ lá»i Ä‘Ãºng trÃªn Internet khÃ´ng pháº£i lÃ  Ä‘áº·t cÃ¢u há»i, mÃ  lÃ  Ä‘Äƒng lÃªn má»™t cÃ¢u tráº£ lá»i sai.". McGeady Ä‘áº·t tÃªn cho luáº­t nÃ y lÃ  ***Luáº­t Cunningham***, tuy nhiÃªn Cunningham phá»§ nháº­n Ä‘iá»u nÃ y vÃ  gá»i Ä‘Ã¢y lÃ  má»™t "trÃ­ch dáº«n sai". Máº·c dÃ¹ ban Ä‘áº§u nÃ³ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ nÃ³i vá» tÆ°Æ¡ng tÃ¡c trÃªn Usenet, luáº­t nÃ y cÅ©ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ mÃ´ táº£ cÃ¡ch mÃ  cÃ¡c cá»™ng Ä‘á»“ng trá»±c tuyáº¿n khÃ¡c hoáº¡t Ä‘á»™ng (vÃ­ dá»¥: Wikipedia, Reddit, Twitter, Facebook).

Xem thÃªm:

- [XKCD 386: "Duty Calls"](https://xkcd.com/386/)

### Sá»‘ Dunbar

[Sá»‘ Dunbar xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Dunbar%27s_number)

Sá»‘ Dunbar Ä‘Æ°á»£c Ä‘á» xuáº¥t nhÆ° lÃ  má»™t giá»›i háº¡n nháº­n thá»©c Ä‘á»ƒ chá»‰ sá»‘ lÆ°á»£ng ngÆ°á»i tá»‘i Ä‘a mÃ  má»™t cÃ¡ nhÃ¢n cÃ³ thá»ƒ duy trÃ¬ má»‘i quan há»‡ xÃ£ há»™i á»•n Ä‘á»‹nh (nhá»¯ng má»‘i quan há»‡ mÃ  trong Ä‘Ã³ má»™t ngÆ°á»i biáº¿t nhá»¯ng ngÆ°á»i cÃ²n láº¡i vÃ  má»‘i liÃªn há»‡ cá»§a há» vá»›i nhá»¯ng ngÆ°á»i khÃ¡c). DÃ¹ cÃ³ má»™t vÃ i báº¥t Ä‘á»“ng trong con sá»‘ chÃ­nh xÃ¡c, nhÆ°ng Dunbar cho ráº±ng má»—i ngÆ°á»i chá»‰ cÃ³ thá»ƒ thoáº£i mÃ¡i duy trÃ¬ 150 quan há»‡ á»•n Ä‘á»‹nh. Ã”ng áº¥y Ä‘áº·t con sá»‘ nÃ y trong má»™t hoÃ n cáº£nh xÃ£ há»™i cá»¥ thá»ƒ: "ÄÃ³ lÃ  sá»‘ ngÆ°á»i mÃ  báº¡n cÃ³ thá»ƒ thoáº£i mÃ¡i lÃ m vá»›i há» má»™t ly khi vÃ´ tÃ¬nh gáº·p nhau trong quÃ¡n bar". Æ¯á»›c tÃ­nh vá» con sá»‘ cá»¥ thá»ƒ thÆ°á»ng rÆ¡i vÃ o giá»¯a 100 vÃ  250.

CÅ©ng giá»‘ng nhÆ° nhá»¯ng má»‘i quan há»‡ á»•n Ä‘á»‹nh giá»¯a ngÆ°á»i vá»›i ngÆ°á»i, má»‘i quan há»‡ cá»§a má»™t nhÃ  phÃ¡t triá»ƒn vá»›i mÃ£ nguá»“n cá»§a há» cÅ©ng Ä‘Ã²i há»i ná»— lá»±c Ä‘á»ƒ duy trÃ¬. Khi pháº£i Ä‘á»‘i máº·t vá»›i nhá»¯ng dá»± Ã¡n lá»›n vÃ  phá»©c táº¡p, hay khi pháº£i lÃ m chá»§ quÃ¡ nhiá»u dá»± Ã¡n, chÃºng ta thÆ°á»ng dá»±a vÃ o cÃ¡c quy Æ°á»›c, luáº­t lá»‡ vÃ  cÃ¡c quy trÃ¬nh Ä‘Ã£ Ä‘Æ°á»£c mÃ´ hÃ¬nh hÃ³a Ä‘á»ƒ má»Ÿ rá»™ng. Sá»‘ Dunbar khÃ´ng chá»‰ quan trá»ng vÃ  cáº§n Ä‘Æ°á»£c ghi nhá»› khi phÃ¡t triá»ƒn tá»• chá»©c, mÃ  cÃ²n Ã¡p dá»¥ng khi Ä‘áº·t ra giá»›i háº¡n cho ná»— lá»±c cá»§a Ä‘á»™i nhÃ³m hay khi Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh ráº±ng má»™t há»‡ thá»‘ng cÃ³ nÃªn Ä‘áº§u tÆ° vÃ o cÃ¡c cÃ´ng cá»¥ Ä‘á»ƒ há»— trá»£ viá»‡c mÃ´ hÃ¬nh hÃ³a vÃ  tá»± Ä‘á»™ng hÃ³a cÃ¡c cÃ´ng viá»‡c háº­u cáº§n hay khÃ´ng. Äáº·t con sá»‘ nÃ y vÃ o mÃ´i trÆ°á»ng kÄ© thuáº­t, Ä‘Ã³ lÃ  sá»‘ lÆ°á»£ng dá»± Ã¡n (hoáº·c cÃ¡c má»©c Ä‘á»™ phá»©c táº¡p cá»§a má»™t dá»± Ã¡n) mÃ  báº¡n cÃ³ thá»ƒ tá»± tin tham gia vÃ o khi Ä‘Æ°á»£c yÃªu cáº§u há»— trá»£.

Xem thÃªm:

- [Luáº­t Conway](#lu%e1%ba%adt-conway)

### Luáº­t Gall

[Luáº­t Gall xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/John_Gall_(author)#Gall's_law)

> Má»™t há»‡ thá»‘ng phá»©c táº¡p hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c luÃ´n luÃ´n phÃ¡t triá»ƒn tá»« má»™t há»‡ thá»‘ng Ä‘Æ¡n giáº£n hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c. Má»™t há»‡ thá»‘ng Ä‘Æ°á»£c thiáº¿t káº¿ phá»©c táº¡p tá»« Ä‘áº§u sáº½ khÃ´ng bao giá» hoáº¡t Ä‘á»™ng dÃ¹ cÃ³ cá»‘ vÃ¡ vÃ­u nhÆ° tháº¿ nÃ o. Báº¡n pháº£i báº¯t Ä‘áº§u vá»›i má»™t há»‡ thá»‘ng Ä‘Æ¡n giáº£n, hoáº¡t Ä‘á»™ng Ä‘Æ°á»£c trÆ°á»›c.
> ([John Gall](https://en.wikipedia.org/wiki/John_Gall_(author)))

Luáº­t Gall chá»‰ ra ráº±ng viá»‡c cá»‘ gáº¯ng _thiáº¿t káº¿_ nhá»¯ng há»‡ thá»‘ng cá»±c kÃ¬ phá»©c táº¡p thÆ°á»ng dá»… dáº«n tá»›i tháº¥t báº¡i. Nhá»¯ng há»‡ thá»‘ng nhÆ° váº­y thÆ°á»ng Ã­t khi Ä‘Æ°á»£c xÃ¢y dá»±ng phá»©c táº¡p tá»« Ä‘áº§u, thay vÃ o Ä‘Ã³ lÃ  Ä‘Æ°á»£c phÃ¡t triá»ƒn tá»« nhiá»u há»‡ thá»‘ng Ä‘Æ¡n giáº£n hÆ¡n.

VÃ­ dá»¥ kinh Ä‘iá»ƒn cho luáº­t nÃ y chÃ­nh lÃ  máº¡ng world-wide-web (WWW). á» tráº¡ng thÃ¡i hiá»‡n táº¡i, nÃ³ lÃ  má»™t há»‡ thá»‘ng cá»±c kÃ¬ phá»©c táº¡p. Tuy nhiÃªn, ban Ä‘áº§u nÃ³ chá»‰ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a nhÆ° lÃ  má»™t cÃ¡ch thá»©c Ä‘Æ¡n giáº£n Ä‘á»ƒ chia sáº» ná»™i dung giá»¯a cÃ¡c tá»• chá»©c há»c thuáº­t. NÃ³ Ä‘Ã£ hoÃ n thÃ nh má»¥c tiÃªu Ä‘Ã³ ráº¥t thÃ nh cÃ´ng vÃ  phÃ¡t triá»ƒn Ä‘á»ƒ trá»Ÿ nÃªn phá»©c táº¡p hÆ¡n theo thá»i gian.
Xem thÃªm:

- [NguyÃªn táº¯c KISS](#nguy%c3%aan-t%e1%ba%afc-kiss)

### Luáº­t Goodhart

[Luáº­t Goodhart xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Goodhart's_law)
> Báº¥t ká»³ chá»‰ sá»‘ thá»‘ng kÃª nÃ o cÅ©ng cÃ³ xu hÆ°á»›ng sá»¥p Ä‘á»• má»™t khi Ã¡p lá»±c Ä‘Æ°á»£c Ä‘áº·t vÃ o nÃ³ cho má»¥c Ä‘Ã­ch kiá»ƒm soÃ¡t.
> 
> _Charles Goodhart_

NÃ³i cÃ¡ch khÃ¡c:

> Khi má»™t chá»‰ sá»‘ trá»Ÿ thÃ nh má»¥c tiÃªu, nÃ³ khÃ´ng cÃ²n lÃ  má»™t chá»‰ sá»‘ tá»‘t ná»¯a.
>
> _Marilyn Strathern_

Luáº­t nÃ y chá»‰ ra ráº±ng viá»‡c tá»‘i Æ°u hÃ³a theo chá»‰ sá»‘ cÃ³ thá»ƒ dáº«n tá»›i sá»± giáº£m giÃ¡ trá»‹ cá»§a chÃ­nh chá»‰ sá»‘ Ä‘Ã³. 
Táº­p há»£p cÃ¡c chá»‰ tiÃªu bá»‹ lá»±a chá»n quÃ¡ má»©c ([KPIs](https://en.wikipedia.org/wiki/Performance_indicator)) má»™t cÃ¡ch mÃ¹ quÃ¡ng khi Ã¡p dá»¥ng vÃ o má»™t quÃ¡ trÃ¬nh thÆ°á»ng dáº«n tá»›i nhá»¯ng hiá»‡u á»©ng mÃ©o mÃ³. NgÆ°á»i ta cÃ³ xu hÆ°á»›ng tá»‘i Æ°u cá»¥c bá»™ báº±ng cÃ¡ch "thÆ°á»Ÿng nÃ³ng" há»‡ thá»‘ng Ä‘á»ƒ thá»a mÃ£n má»™t táº­p chá»‰ sá»‘ nháº¥t Ä‘á»‹nh thay vÃ¬ táº­p trung vÃ o káº¿t quáº£ toÃ n diá»‡n cá»§a hÃ nh Ä‘á»™ng cá»§a há».

VÃ­ dá»¥ thá»±c táº¿:
- CÃ¡c kiá»ƒm thá»­ khÃ´ng xÃ¡c minh (assert-free tests) chá»‰ thoáº£ mÃ£n yÃªu cáº§u vá» Ä‘á»™ bao phá»§ mÃ£, máº·c dÃ¹ má»¥c Ä‘Ã­ch cá»§a nÃ³ lÃ  táº¡o ra má»™t pháº§n má»m Ä‘Æ°á»£c kiá»ƒm thá»­ tá»‘t.
- Hiá»‡u suáº¥t cá»§a nhÃ  phÃ¡t triá»ƒn náº¿u Ä‘Æ°á»£c Ä‘o báº±ng sá»‘ lÆ°á»£ng dÃ²ng mÃ£ sáº½ dáº«n tá»›i há»‡ thá»‘ng mÃ£ nguá»“n cá»“ng ká»nh khÃ´ng cáº§n thiáº¿t.

Xem thÃªm:
- [Goodhartâ€™s Law: How Measuring The Wrong Things Drive Immoral Behaviour](https://coffeeandjunk.com/goodharts-campbells-law/)
- [Dilbert on bug-free software](https://dilbert.com/strip/1995-11-13)

### Hanlon's Razor

[Hanlon's Razor on Wikipedia](https://en.wikipedia.org/wiki/Hanlon%27s_razor)

> Never attribute to malice that which is adequately explained by stupidity.
>
> Robert J. Hanlon

This principle suggests that actions resulting in a negative outcome were not a result of ill will. Instead the negative outcome is more likely attributed to those actions and/or the impact being not fully understood.

### Hofstadter's Law

[Hofstadter's Law on Wikipedia](https://en.wikipedia.org/wiki/Hofstadter%27s_law)

> It always takes longer than you expect, even when you take into account Hofstadter's Law.
>
> (Douglas Hofstadter)

You might hear this law referred to when looking at estimates for how long something will take. It seems a truism in software development that we tend to not be very good at accurately estimating how long something will take to deliver.

This is from the book '[GÃ¶del, Escher, Bach: An Eternal Golden Braid](#reading-list)'.

See also:

- [Reading List: GÃ¶del, Escher, Bach: An Eternal Golden Braid](#reading-list)

### Hutber's Law

[Hutber's Law on Wikipedia](https://en.wikipedia.org/wiki/Hutber%27s_law)

> Improvement means deterioration.
>
> ([Patrick Hutber](https://en.wikipedia.org/wiki/Patrick_Hutber))

This law suggests that improvements to a system will lead to deterioration in other parts, or it will hide other deterioration, leading overall to a degradation from the current state of the system.

For example, a decrease in response latency for a particular end-point could cause increased throughput and capacity issues further along in a request flow, affecting an entirely different sub-system.

### The Hype Cycle & Amara's Law

[The Hype Cycle on Wikipedia](https://en.wikipedia.org/wiki/Hype_cycle)

> We tend to overestimate the effect of a technology in the short run and underestimate the effect in the long run.
>
> (Roy Amara)

The Hype Cycle is a visual representation of the excitement and development of technology over time, originally produced by Gartner. It is best shown with a visual:

![The Hype Cycle](./images/gartner_hype_cycle.png)

*(Image Reference: By Jeremykemp at English Wikipedia, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=10547051)*

In short, this cycle suggests that there is typically a burst of excitement around new technology and its potential impact. Teams often jump into these technologies quickly, and sometimes find themselves disappointed with the results. This might be because the technology is not yet mature enough, or real-world applications are not yet fully realised. After a certain amount of time, the capabilities of the technology increase and practical opportunities to use it increase, and teams can finally become productive. Roy Amara's quote sums this up most succinctly - "We tend to overestimate the effect of a technology in the short run and underestimate in the long run".

### Hyrum's Law (The Law of Implicit Interfaces)

[Hyrum's Law Online](http://www.hyrumslaw.com/)

> With a sufficient number of users of an API,
> it does not matter what you promise in the contract:
> all observable behaviours of your system
> will be depended on by somebody.
>
> (Hyrum Wright)

Hyrum's Law states that when you have a _large enough number of consumers_ of an API, all behaviours of the API (even those not defined as part of a public contract) will eventually come to be depended on by someone. A trivial example may be non-functional elements such as the response time of an API. A more subtle example might be consumers who are relying on applying a regex to an error message to determine the *type* of error of an API. Even if the public contract of the API states nothing about the contents of the message, indicating users should use an associated error code, _some_ users may use the message, and changing the message essentially breaks the API for those users.

See also:

- [The Law of Leaky Abstractions](#the-law-of-leaky-abstractions)
- [XKCD 1172](https://xkcd.com/1172/)

### Kernighan's Law

> Debugging is twice as hard as writing the code in the first place. Therefore, if you write the code as cleverly as possible, you are, by definition, not smart enough to debug it.
>
> (Brian Kernighan)

Kernighan's Law is named for [Brian Kernighan](https://en.wikipedia.org/wiki/Brian_Kernighan) and derived from a quote from Kernighan and Plauger's book [The Elements of Programming Style](https://en.wikipedia.org/wiki/The_Elements_of_Programming_Style):

> Everyone knows that debugging is twice as hard as writing a program in the first place. So if you're as clever as you can be when you write it, how will you ever debug it?

While hyperbolic, Kernighan's Law makes the argument that simple code is to be preferred over complex code, because debugging any issues that arise in complex code may be costly or even infeasible.

See also:

- [The KISS Principle](#the-kiss-principle)
- [The Unix Philosophy](#the-unix-philosophy)
- [Occam's Razor](#occams-razor)

### Metcalfe's Law

[Metcalfe's Law on Wikipedia](https://en.wikipedia.org/wiki/Metcalfe's_law)

> In network theory, the value of a system grows as approximately the square of the number of users of the system.

This law is based on the number of possible pairwise connections within a system and is closely related to [Reed's Law](#reeds-law). Odlyzko and others have argued that both Reed's Law and Metcalfe's Law overstate the value of the system by not accounting for the limits of human cognition on network effects; see [Dunbar's Number](#dunbars-number).

See also:
- [Reed's Law](#reeds-law)
- [Dunbar's Number](#dunbars-number)

### Moore's Law

[Moore's Law on Wikipedia](https://en.wikipedia.org/wiki/Moore%27s_law)

> The number of transistors in an integrated circuit doubles approximately every two years.

Often used to illustrate the sheer speed at which semiconductor and chip technology has improved, Moore's prediction has proven to be highly accurate over from the 1970s to the late 2000s. In more recent years, the trend has changed slightly, partly due to [physical limitations on the degree to which components can be miniaturised](https://en.wikipedia.org/wiki/Quantum_tunnelling). However, advancements in parallelisation, and potentially revolutionary changes in semiconductor technology and quantum computing may mean that Moore's Law could continue to hold true for decades to come.

### Murphy's Law / Sod's Law

[Murphy's Law on Wikipedia](https://en.wikipedia.org/wiki/Murphy%27s_law)

> Anything that can go wrong will go wrong.

Related to [Edward A. Murphy, Jr](https://en.wikipedia.org/wiki/Edward_A._Murphy_Jr.) _Murphy's Law_ states that if a thing can go wrong, it will go wrong.

This is a common adage among developers. Sometimes the unexpected happens when developing, testing or even in production. This can also be related to the (more common in British English) _Sod's Law_:

> If something can go wrong, it will, at the worst possible time.

These 'laws' are generally used in a comic sense. However, phenomena such as [_Confirmation Bias_](#TODO) and [_Selection Bias_](#TODO) can lead people to perhaps over-emphasise these laws (the majority of times when things work, they go unnoticed, failures however are more noticeable and draw more discussion).

See Also:

- [Confirmation Bias](#TODO)
- [Selection Bias](#TODO)

### Occam's Razor

[Occam's Razor on Wikipedia](https://en.wikipedia.org/wiki/Occam's_razor)

> Entities should not be multiplied without necessity.
>
> William of Ockham

Occam's razor says that among several possible solutions, the most likely solution is the one with the least number of concepts and assumptions. This solution is the simplest and solves only the given problem, without introducing accidental complexity and possible negative consequences.

See also:

- [YAGNI](#yagni)
- [No Silver Bullet: Accidental Complexity and Essential Complexity](https://en.wikipedia.org/wiki/No_Silver_Bullet)

Example:

- [Lean Software Development: Eliminate Waste](https://en.wikipedia.org/wiki/Lean_software_development#Eliminate_waste)

### Parkinson's Law

[Parkinson's Law on Wikipedia](https://en.wikipedia.org/wiki/Parkinson%27s_law)

> Work expands so as to fill the time available for its completion.

In its original context, this Law was based on studies of bureaucracies. It may be pessimistically applied to software development initiatives, the theory being that teams will be inefficient until deadlines near, then rush to complete work by the deadline, thus making the actual deadline somewhat arbitrary.

If this law were combined with [Hofstadter's Law](#hofstadters-law), an even more pessimistic viewpoint is reached - work will expand to fill the time available for its completion and *still take longer than expected*.

See also:

- [Hofstadter's Law](#hofstadters-law)

### Premature Optimization Effect

[Premature Optimization on WikiWikiWeb](http://wiki.c2.com/?PrematureOptimization)

> Premature optimization is the root of all evil.
>
> [(Donald Knuth)](https://twitter.com/realdonaldknuth?lang=en)

In Donald Knuth's paper [Structured Programming With Go To Statements](http://wiki.c2.com/?StructuredProgrammingWithGoToStatements), he wrote: "Programmers waste enormous amounts of time thinking about, or worrying about, the speed of noncritical parts of their programs, and these attempts at efficiency actually have a strong negative impact when debugging and maintenance are considered. We should forget about small efficiencies, say about 97% of the time: **premature optimization is the root of all evil**. Yet we should not pass up our opportunities in that critical 3%."

However, _Premature Optimization_ can be defined (in less loaded terms) as optimizing before we know that we need to.

### Putt's Law

[Putt's Law on Wikipedia](https://en.wikipedia.org/wiki/Putt%27s_Law_and_the_Successful_Technocrat)

> Technology is dominated by two types of people, those who understand what they do not manage and those who manage what they do not understand.

Putt's Law is often followed by Putt's Corollary:

> Every technical hierarchy, in time, develops a competence inversion.

These statements suggest that due to various selection criteria and trends in how groups organise, there will be a number of skilled people at working levels of a technical organisations, and a number of people in managerial roles who are not aware of the complexities and challenges of the work they are managing. This can be due to phenomena such as [The Peter Principle](#the-peter-principle) or [The Dilbert Principle](#the-dilbert-principle).

However, it should be stressed that Laws such as this are vast generalisations and may apply to _some_ types of organisations, and not apply to others.

See also:

- [The Peter Principle](#the-peter-principle)
- [The Dilbert Principle](#the-dilbert-principle)


### Reed's Law

[Reed's Law on Wikipedia](https://en.wikipedia.org/wiki/Reed's_law)

> The utility of large networks, particularly social networks, scales exponentially with the size of the network.

This law is based on graph theory, where the utility scales as the number of possible sub-groups, which is faster than the number of participants or the number of possible pairwise connections. Odlyzko and others have argued that Reed's Law overstates the utility of the system by not accounting for the limits of human cognition on network effects; see [Dunbar's Number](#dunbars-number).

See also:
- [Metcalfe's Law](#metcalfes-law)
- [Dunbar's Number](#dunbars-number)

### The Law of Conservation of Complexity (Tesler's Law)

[The Law of Conservation of Complexity on Wikipedia](https://en.wikipedia.org/wiki/Law_of_conservation_of_complexity)

This law states that there is a certain amount of complexity in a system which cannot be reduced.

Some complexity in a system is 'inadvertent'. It is a consequence of poor structure, mistakes, or just bad modeling of a problem to solve. Inadvertent complexity can be reduced (or eliminated). However, some complexity is 'intrinsic' as a consequence of the complexity inherent in the problem being solved. This complexity can be moved, but not eliminated.

One interesting element to this law is the suggestion that even by simplifying the entire system, the intrinsic complexity is not reduced, it is _moved to the user_, who must behave in a more complex way.

### The Law of Leaky Abstractions

[The Law of Leaky Abstractions on Joel on Software](https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/)

> All non-trivial abstractions, to some degree, are leaky.
>
> ([Joel Spolsky](https://twitter.com/spolsky))

This law states that abstractions, which are generally used in computing to simplify working with complicated systems, will in certain situations 'leak' elements of the underlying system, this making the abstraction behave in an unexpected way.

An example might be loading a file and reading its contents. The file system APIs are an _abstraction_ of the lower level kernel systems, which are themselves an abstraction over the physical processes relating to changing data on a magnetic platter (or flash memory for an SSD). In most cases, the abstraction of treating a file like a stream of binary data will work. However, for a magnetic drive, reading data sequentially will be *significantly* faster than random access (due to increased overhead of page faults), but for an SSD drive, this overhead will not be present. Underlying details will need to be understood to deal with this case (for example, database index files are structured to reduce the overhead of random access), the abstraction 'leaks' implementation details the developer may need to be aware of.

The example above can become more complex when _more_ abstractions are introduced. The Linux operating system allows files to be accessed over a network but represented locally as 'normal' files. This abstraction will 'leak' if there are network failures. If a developer treats these files as 'normal' files, without considering the fact that they may be subject to network latency and failures, the solutions will be buggy.

The article describing the law suggests that an over-reliance on abstractions, combined with a poor understanding of the underlying processes, actually makes dealing with the problem at hand _more_ complex in some cases.

See also:

- [Hyrum's Law](#hyrums-law-the-law-of-implicit-interfaces)

Real-world examples:

- [Photoshop Slow Startup](https://forums.adobe.com/thread/376152) - an issue I encountered in the past. Photoshop would be slow to startup, sometimes taking minutes. It seems the issue was that on startup it reads some information about the current default printer. However, if that printer is actually a network printer, this could take an extremely long time. The _abstraction_ of a network printer being presented to the system similar to a local printer caused an issue for users in poor connectivity situations.

### The Law of Triviality

[The Law of Triviality on Wikipedia](https://en.wikipedia.org/wiki/Law_of_triviality)

This law suggests that groups will give far more time and attention to trivial or cosmetic issues rather than serious and substantial ones.

The common fictional example used is that of a committee approving plans for nuclear power plant, who spend the majority of their time discussing the structure of the bike shed, rather than the far more important design for the power plant itself. It can be difficult to give valuable input on discussions about very large, complex topics without a high degree of subject matter expertise or preparation. However, people want to be seen to be contributing valuable input. Hence a tendency to focus too much time on small details, which can be reasoned about easily, but are not necessarily of particular importance.

The fictional example above led to the usage of the term 'Bike Shedding' as an expression for wasting time on trivial details. An alternative term is 'Yak Shaving'.

### The Unix Philosophy

[The Unix Philosophy on Wikipedia](https://en.wikipedia.org/wiki/Unix_philosophy)

The Unix Philosophy is that software components should be small, and focused on doing one specific thing well. This can make it easier to build systems by composing together small, simple, well-defined units, rather than using large, complex, multi-purpose programs.

Modern practices like 'Microservice Architecture' can be thought of as an application of this law, where services are small, focused and do one specific thing, allowing complex behaviour to be composed of simple building blocks.

### MÃ´ hÃ¬nh Spotify

[MÃ´ hÃ¬nh Spotify xem táº¡i Spotify Labs](https://labs.spotify.com/2014/03/27/spotify-engineering-culture-part-1/)

MÃ´ hÃ¬nh Spotify lÃ  má»™t cÃ¡ch tiáº¿p cáº­n trong viá»‡c xÃ¢y dá»±ng cáº¥u trÃºc cho Ä‘á»™i nhÃ³m vÃ  tá»• chá»©c, Ä‘Æ°á»£c phá»• biáº¿n bá»Ÿi 'Spotify'. Trong mÃ´ hÃ¬nh nÃ y, cÃ¡c Ä‘á»™i nhÃ³m Ä‘Æ°á»£c táº­p trung xÃ¢y dá»±ng xung quanh tÃ­nh nÄƒng thay vÃ¬ cÃ´ng nghá»‡. 

MÃ´ hÃ¬nh Spotify cÅ©ng phá»• biáº¿n cÃ¡c khÃ¡i niá»‡m vá» **Tribes**, **Guilds** hay **Chapters**, lÃ  nhá»¯ng thÃ nh pháº§n khÃ¡c trong cáº¥u trÃºc tá»• chá»©c cá»§a há».

### Wadler's Law

[Wadler's Law on wiki.haskell.org](https://wiki.haskell.org/Wadler's_Law)

> In any language design, the total time spent discussing a feature in this list is proportional to two raised to the power of its position.
>
> 0. Semantics
> 1. Syntax
> 2. Lexical syntax
> 3. Lexical syntax of comments
>
> (In short, for every hour spent on semantics, 8 hours will be spent on the syntax of comments).

Similar to [The Law of Triviality](#the-law-of-triviality), Wadler's Law states what when designing a language, the amount of time spent on language structures is disproportionately high in comparison to the importance of those features.

See also:

- [The Law of Triviality](#the-law-of-triviality)

### Wheaton's Law

[The Link](http://www.wheatonslaw.com/)

[The Official Day](https://dontbeadickday.com/)

> Don't be a dick.
>
> _Wil Wheaton_

Coined by Wil Wheaton (Star Trek: The Next Generation, The Big Bang Theory), this simple, concise, and powerful law aims for an increase in harmony and respect within a professional organization. It can be applied when speaking with coworkers, performing code reviews, countering other points of view, critiquing, and in general, most professional interactions humans have with each other.

## Principles

Principles are generally more likely to be guidelines relating to design.

### The Dilbert Principle

[The Dilbert Principle on Wikipedia](https://en.wikipedia.org/wiki/Dilbert_principle)

> Companies tend to systematically promote incompetent employees to management to get them out of the workflow.
>
> _Scott Adams_

A management concept developed by Scott Adams (creator of the Dilbert comic strip), the Dilbert Principle is inspired by [The Peter Principle](#the-peter-principle). Under the Dilbert Principle, employees who were never competent are promoted to management in order to limit the damage they can do. Adams first explained the principle in a 1995 Wall Street Journal article, and expanded upon it in his 1996 business book, [The Dilbert Principle](#reading-list).

See Also:

- [The Peter Principle](#the-peter-principle)
- [Putt's Law](#putts-law)

### The Pareto Principle (The 80/20 Rule)

[The Pareto Principle on Wikipedia](https://en.wikipedia.org/wiki/Pareto_principle)

> Most things in life are not distributed evenly.

The Pareto Principle suggests that in some cases, the majority of results come from a minority of inputs:

- 80% of a certain piece of software can be written in 20% of the total allocated time (conversely, the hardest 20% of the code takes 80% of the time)
- 20% of the effort produces 80% of the result
- 20% of the work creates 80% of the revenue
- 20% of the bugs cause 80% of the crashes
- 20% of the features cause 80% of the usage

In the 1940s American-Romanian engineer Dr. Joseph Juran, who is widely credited with being the father of quality control, [began to apply the Pareto principle to quality issues](https://en.wikipedia.org/wiki/Joseph_M._Juran).

This principle is also known as: The 80/20 Rule, The Law of the Vital Few and The Principle of Factor Sparsity.

Real-world examples:

- In 2002 Microsoft reported that by fixing the top 20% of the most-reported bugs, 80% of the related errors and crashes in windows and office would become eliminated ([Reference](https://www.crn.com/news/security/18821726/microsofts-ceo-80-20-rule-applies-to-bugs-not-just-features.htm)).

### The Peter Principle

[The Peter Principle on Wikipedia](https://en.wikipedia.org/wiki/Peter_principle)

> People in a hierarchy tend to rise to their "level of incompetence".
>
> _Laurence J. Peter_

A management concept developed by Laurence J. Peter, the Peter Principle observes that people who are good at their jobs are promoted, until they reach a level where they are no longer successful (their "level of incompetence". At this point, as they are more senior, they are less likely to be removed from the organisation (unless they perform spectacularly badly) and will continue to reside in a role which they have few intrinsic skills at, as their original skills which made them successful are not necessarily the skills required for their new jobs.

This is of particular interest to engineers - who initial start out in deeply technical roles, but often have a career path which leads to _managing_ other engineers - which requires a fundamentally different skills-set.

See Also:

- [The Dilbert Principle](#the-dilbert-principle)
- [Putt's Law](#putts-law)

### The Robustness Principle (Postel's Law)

[The Robustness Principle on Wikipedia](https://en.wikipedia.org/wiki/Robustness_principle)

> Be conservative in what you do, be liberal in what you accept from others.

Often applied in server application development, this principle states that what you send to others should be as minimal and conformant as possible, but you should be aim to allow non-conformant input if it can be processed.

The goal of this principle is to build systems which are robust, as they can handle poorly formed input if the intent can still be understood. However, there are potentially security implications of accepting malformed input, particularly if the processing of such input is not well tested.

Allowing non-conformant input, in time, may undermine the ability of protocols to evolve as implementors will eventually rely on this liberality to build their features.

See Also:

- [Hyrum's Law](#hyrums-law-the-law-of-implicit-interfaces)


### SOLID

This is an acronym, which refers to:

* S: [The Single Responsibility Principle](#the-single-responsibility-principle)
* O: [The Open/Closed Principle](#the-openclosed-principle)
* L: [The Liskov Substitution Principle](#the-liskov-substitution-principle)
* I: [The Interface Segregation Principle](#the-interface-segregation-principle)
* D: [The Dependency Inversion Principle](#the-dependency-inversion-principle)

These are key principles in [Object-Oriented Programming](#todo). Design principles such as these should be able to aid developers build more maintainable systems.

### The Single Responsibility Principle

[The Single Responsibility Principle on Wikipedia](https://en.wikipedia.org/wiki/Single_responsibility_principle)

> Every module or class should have a single responsibility only.

The first of the '[SOLID](#solid)' principles. This principle suggests that modules or classes should do one thing and one thing only. In more practical terms, this means that a single, small change to a feature of a program should require a change in one component only. For example, changing how a password is validated for complexity should require a change in only one part of the program.

Theoretically, this should make the code more robust, and easier to change. Knowing that a component which is being changed has a single responsibility only means that _testing_ that change should be easier. Using the earlier example, changing the password complexity component should only be able to affect the features which relate to password complexity. It can be much more difficult to reason about the impact of a change to a component which has many responsibilities.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Open/Closed Principle

[The Open/Closed Principle on Wikipedia](https://en.wikipedia.org/wiki/Open%E2%80%93closed_principle)

> Entities should be open for extension and closed for modification.

The second of the '[SOLID](#solid)' principles. This principle states that entities (which could be classes, modules, functions and so on) should be able to have their behaviour _extended_, but that their _existing_ behaviour should not be able to be modified.

As a hypothetical example, imagine a module which is able to turn a Markdown document into HTML. If the module could be extended to handle a newly proposed markdown feature, without modifying the module internals, then it would be open for extension. If the module could _not_ be modified by a consumer so that how existing Markdown features are handled, then it would be _closed_ for modification.

This principle has particular relevance for object-oriented programming, where we may design objects to be easily extended, but would avoid designing objects which can have their existing behaviour changed in unexpected ways.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Liskov Substitution Principle

[The Liskov Substitution Principle on Wikipedia](https://en.wikipedia.org/wiki/Liskov_substitution_principle)

> It should be possible to replace a type with a subtype, without breaking the system.

The third of the '[SOLID](#solid)' principles. This principle states that if a component relies on a type, then it should be able to use subtypes of that type, without the system failing or having to know the details of what that subtype is.

As an example, imagine we have a method which reads an XML document from a structure which represents a file. If the method uses a base type 'file', then anything which derives from 'file' should be able to be used in the function. If 'file' supports seeking in reverse, and the XML parser uses that function, but the derived type 'network file' fails when reverse seeking is attempted, then the 'network file' would be violating the principle.

This principle has particular relevance for object-oriented programming, where type hierarchies must be modeled carefully to avoid confusing users of a system.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)

### The Interface Segregation Principle

[The Interface Segregation Principle on Wikipedia](https://en.wikipedia.org/wiki/Interface_segregation_principle)

> No client should be forced to depend on methods it does not use.

The fourth of the '[SOLID](#solid)' principles. This principle states that consumers of a component should not depend on functions of that component which it doesn't actually use.

As an example, imagine we have a method which reads an XML document from a structure which represents a file. It only needs to read bytes, move forwards or move backwards in the file. If this method needs to be updated because an unrelated feature of the file structure changes (such as an update to the permissions model used to represent file security), then the principle has been invalidated. It would be better for the file to implement a 'seekable-stream' interface, and for the XML reader to use that.

This principle has particular relevance for object-oriented programming, where interfaces, hierarchies and abstract types are used to [minimise the coupling](#todo) between different components. [Duck typing](#todo) is a methodology which enforces this principle by eliminating explicit interfaces.

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)
- [Duck Typing](#todo)
- [Decoupling](#todo)

### The Dependency Inversion Principle

[The Dependency Inversion Principle on Wikipedia](https://en.wikipedia.org/wiki/Dependency_inversion_principle)

> High-level modules should not be dependent on low-level implementations.

The fifth of the '[SOLID](#solid)' principles. This principle states that higher level orchestrating components should not have to know the details of their dependencies.

As an example, imagine we have a program which read metadata from a website. We would assume that the main component would have to know about a component to download the webpage content, then a component which can read the metadata. If we were to take dependency inversion into account, the main component would depend only on an abstract component which can fetch byte data, and then an abstract component which would be able to read metadata from a byte stream. The main component would not know about TCP/IP, HTTP, HTML, etc.

This principle is complex, as it can seem to 'invert' the expected dependencies of a system (hence the name). In practice, it also means that a separate orchestrating component must ensure the correct implementations of abstract types are used (e.g. in the previous example, _something_ must still provide the metadata reader component a HTTP file downloader and HTML meta tag reader). This then touches on patterns such as [Inversion of Control](#todo) and [Dependency Injection](#todo).

See also:

- [Object-Oriented Programming](#todo)
- [SOLID](#solid)
- [Inversion of Control](#todo)
- [Dependency Injection](#todo)

### NguyÃªn táº¯c DRY

[NguyÃªn táº¯c DRY xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Don%27t_repeat_yourself)

> Trong má»™t há»‡ thá»‘ng, má»—i thÃ nh pháº§n pháº£i cÃ³ má»™t mÃ´ táº£ duy nháº¥t, khÃ´ng mÆ¡ há»“ vÃ  cháº¯c cháº¯n.

DRY lÃ  viáº¿t táº¯t cá»§a _Don't Repeat Yourself_, _Äá»«ng Láº·p Láº¡i ChÃ­nh Báº¡n_. Má»¥c tiÃªu cá»§a nguyÃªn táº¯c nÃ y lÃ  Ä‘á»ƒ giÃºp nhÃ  phÃ¡t triá»ƒn giáº£m viá»‡c láº·p láº¡i mÃ£ nguá»“n vÃ  giá»¯ thÃ´ng tin á»Ÿ má»™t nÆ¡i duy nháº¥t, nguyÃªn táº¯c nÃ y Ä‘Ã£ Ä‘Æ°á»£c trÃ­ch dáº«n vÃ o nÄƒm 1999 bá»Ÿi Andrew Hunt vÃ  Dave Thomas trong cuá»‘n [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

> TrÃ¡i ngÆ°á»£c vá»›i DRY lÃ  _WET_ (Write Everything Twice, Viáº¿t Má»i Thá»© Hai Láº§n hay We Enjoy Typing, ChÃºng TÃ´i ThÃ­ch GÃµ).

Trong thá»±c hÃ nh, náº¿u báº¡n cÃ³ pháº§n thÃ´ng tin giá»‘ng nhau trong hai (hoáº·c nhiá»u) nÆ¡i khÃ¡c nhau, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng DRY Ä‘á»ƒ há»£p nháº¥t chÃºng thÃ nh má»™t vÃ  sá»­ dá»¥ng nÃ³ báº¥t ká»³ nÆ¡i nÃ o báº¡n muá»‘n/cáº§n.

Xem thÃªm:

- [The Pragmatic Developer](https://en.wikipedia.org/wiki/The_Pragmatic_Programmer)

### NguyÃªn táº¯c KISS

[KISS xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/KISS_principle)

> Keep it simple, stupid

NguyÃªn táº¯c KISS chá»‰ ra ráº±ng háº§u háº¿t cÃ¡c há»‡ thá»‘ng hoáº¡t Ä‘á»™ng tá»‘t nháº¥t náº¿u nÃ³ Ä‘Æ°á»£c giá»¯ Ä‘Æ¡n giáº£n thay vÃ¬ bá»‹ phá»©c táº¡p hoÃ¡; vÃ¬ váº­y, tÃ­nh Ä‘Æ¡n giáº£n nÃªn lÃ  má»™t má»¥c tiÃªu chÃ­nh trong thiáº¿t káº¿, vÃ  sá»± phá»©c táº¡p khÃ´ng cáº§n thiáº¿t nÃªn Ä‘Æ°á»£c trÃ¡nh. Báº¯t nguá»“n tá»« Háº£i quÃ¢n Má»¹ (U.S Navy) nÄƒm 1960, nguyÃªn táº¯c nÃ y Ä‘Ã£ Ä‘Æ°á»£c gáº¯n liá»n vá»›i tÃªn tuá»•i cá»§a ká»¹ sÆ° hÃ ng khÃ´ng Kelly Johnson.

NguyÃªn táº¯c nÃ y Ä‘Æ°á»£c minh há»a rÃµ nháº¥t qua cÃ¢u chuyá»‡n Johnson trao cho má»™t nhÃ³m ká»¹ sÆ° thiáº¿t káº¿ má»™t sá»‘ Ã­t cÃ¡c cÃ´ng cá»¥, vá»›i thÃ¡ch thá»©c lÃ  mÃ¡y bay pháº£n lá»±c mÃ  há» Ä‘ang thiáº¿t káº¿ pháº£i cÃ³ kháº£ nÄƒng sá»­a chá»¯a Ä‘Æ°á»£c bá»Ÿi má»™t thá»£ mÃ¡y trung bÃ¬nh trong Ä‘iá»u kiá»‡n chiáº¿n Ä‘áº¥u mÃ  chá»‰ báº±ng nhá»¯ng cÃ´ng cá»¥ nÃ y. Do Ä‘Ã³, "stupid" chá»‰ má»‘i quan há»‡ giá»¯a cÃ¡ch má»i thá»© bá»‹ phÃ¡ vá»¡ vÃ  sá»± phá»©c táº¡p cá»§a cÃ¡c cÃ´ng cá»¥ cÃ³ sáºµn Ä‘á»ƒ sá»­a chá»¯a chÃºng, chá»© khÃ´ng pháº£i vá»›i kháº£ nÄƒng cá»§a cÃ¡c ká»¹ sÆ°.

Xem thÃªm::

- [Gall's Law](#galls-law)

### YAGNI

[YAGNI on Wikipedia](https://en.wikipedia.org/wiki/You_ain%27t_gonna_need_it)

ÄÃ¢y lÃ  tá»« viáº¿t táº¯t cá»§a _**Y**ou **A**ren't **G**onna **N**eed **I**t_. (Báº¡n sáº½ khÃ´ng cáº§n nÃ³)

> HÃ£y luÃ´n thá»±c hiá»‡n má»i thá»© khi báº¡n thá»±c sá»± cáº§n chÃºng, chá»© khÃ´ng pháº£i khi báº¡n má»›i chá»‰ tháº¥y trÆ°á»›c ráº±ng báº¡n cáº§n chÃºng.
> (Always implement things when you actually need them, never when you just foresee that you need them.)
> ([Ron Jeffries](https://twitter.com/RonJeffries)) (Äá»“ng sÃ¡ng láº­p XP vÃ  tÃ¡c giáº£ cá»§a cuá»‘n sÃ¡ch "Extreme Programming Installed")

NguyÃªn táº¯c _Extreme Programming_ (XP) nÃ y gá»£i Ã½ ráº±ng cÃ¡c nhÃ  phÃ¡t triá»ƒn chá»‰ nÃªn thá»±c hiá»‡n chá»©c nÄƒng cáº§n thiáº¿t cho cÃ¡c yÃªu cáº§u ngay trÆ°á»›c máº¯t vÃ  trÃ¡nh cÃ¡c ná»— lá»±c dá»± Ä‘oÃ¡n tÆ°Æ¡ng lai báº±ng viá»‡c triá»ƒn khai chá»©c nÄƒng cÃ³ thá»ƒ cáº§n thiáº¿t sau nÃ y.

TuÃ¢n thá»§ nguyÃªn táº¯c nÃ y sáº½ lÃ m giáº£m sá»‘ lÆ°á»£ng Ä‘oáº¡n mÃ£ khÃ´ng Ä‘Æ°á»£c sá»­ dá»¥ng trong toÃ n bá»™ mÃ£ nguá»“n cÅ©ng nhÆ° trÃ¡nh lÃ£ng phÃ­ thá»i gian vÃ  cÃ´ng sá»©c cho cÃ¡c chá»©c nÄƒng khÃ´ng mang láº¡i giÃ¡ trá»‹.

Xem thÃªm:

- [Reading List: Extreme Programming Installed](#reading-list)

### Sá»± áº£o tÆ°á»Ÿng cá»§a Äiá»‡n toÃ¡n PhÃ¢n tÃ¡n

[Tá»« gá»‘c `The Fallacies of Distributed Computing` xem táº¡i Wikipedia](https://en.wikipedia.org/wiki/Fallacies_of_distributed_computing)

CÃ²n Ä‘Æ°á»£c gá»i lÃ  _Sá»± áº£o tÆ°á»Ÿng cá»§a Máº¡ng Äiá»‡n toÃ¡n_, Fallacies lÃ  má»™t danh sÃ¡ch cÃ¡c áº£o tÆ°á»Ÿng (hay niá»m tin) vá» Ä‘iá»‡n toÃ¡n phÃ¢n tÃ¡n, cÃ³ thá»ƒ dáº«n Ä‘áº¿n cÃ¡c tháº¥t báº¡i trong viá»‡c phÃ¡t triá»ƒn pháº§n mÃªmf. CÃ¡c áº£o tÆ°á»Ÿng nÃ y lÃ :

- Máº¡ng luÃ´n tin cáº­y
- Äá»™ trá»… báº±ng 0
- BÄƒng thÃ´ng vÃ´ háº¡n
- Máº¡ng luÃ´n an toÃ n
- Cáº¥u trÃºc máº¡ng (topology) khÃ´ng thay Ä‘á»•i
- CÃ³ má»™t quáº£n trá»‹ viÃªn
- Chi phÃ­ váº­n truyá»n báº±ng 0
- Máº¡ng lÃ  Ä‘á»“ng nháº¥t

Bá»‘n Ã½ Ä‘áº§u tiÃªn Ä‘Æ°á»£c liá»‡t kÃª bá»Ÿi [Bill Joy](https://en.wikipedia.org/wiki/Bill_Joy) and [Tom Lyon](https://twitter.com/aka_pugs) khoáº£ng nÄƒm 1991 vÃ  Ä‘Æ°á»£c phÃ¢n loáº¡i thÃ nh "Fallacies of Networked Computing" láº§n Ä‘áº§u bá»Ÿi [James Gosling](https://en.wikipedia.org/wiki/James_Gosling). [L. Peter Deutsch](https://en.wikipedia.org/wiki/L._Peter_Deutsch) Ä‘Ã£ thÃªm vÃ o danh sÃ¡ch cÃ¡c Ã½ sá»‘ 5, 6 vÃ  7. Cuá»‘i tháº­p niÃªn 90 Gosling Ä‘Ã£ thÃªm vÃ o Ã½ sá»‘ 8.

NhÃ³m Ä‘Æ°á»£c truyá»n cáº£m há»©ng bá»Ÿi nhá»¯ng gÃ¬ Ä‘Ã£ xáº£y ra trong khoáº£ng thá»i gian lÃ m viá»‡c táº¡i [Sun Microsystems](https://en.wikipedia.org/wiki/Sun_Microsystems).

Nhá»¯ng áº£o tÆ°á»Ÿng nÃªn Ä‘Æ°á»£c xem xÃ©t má»™t cÃ¡ch cáº©n tháº­n khi thiáº¿t káº¿ chÆ°Æ¡ng trÃ¬nh; viá»‡c tin vÃ o báº¥t ká»³ cÃ¡c áº£o tÆ°á»Ÿng nÃ o á»Ÿ Ä‘Ã¢y Ä‘á»u cÃ³ thá»ƒ dáº«n tá»›i sá»± thiáº¿u sÃ³t logic, mÃ  khÃ´ng giáº£i quyáº¿t Ä‘Æ°á»£c váº¥n Ä‘á» thá»±c táº¿ vÃ  sá»± phá»©c táº¡p cá»§a cÃ¡c há»‡ thá»‘ng phÃ¢n tÃ¡n.

Xem thÃªm:

- [Foraging for the Fallacies of Distributed Computing (Part 1) - Vaidehi Joshi
 trÃªn Medium](https://medium.com/baseds/foraging-for-the-fallacies-of-distributed-computing-part-1-1b35c3b85b53)
- [Deutsch's Fallacies, 10 Years After](http://java.sys-con.com/node/38665)

## Reading List

If you have found these concepts interesting, you may enjoy the following books.

- [Extreme Programming Installed - Ron Jeffries, Ann Anderson, Chet Hendrikson](https://www.goodreads.com/en/book/show/67834) - Covers the core principles of Extreme Programming.
- [The Mythical Man Month - Frederick P. Brooks Jr.](https://www.goodreads.com/book/show/13629.The_Mythical_Man_Month) - A classic volume on software engineering. [Brooks' Law](#brooks-law) is a central theme of the book.
- [GÃ¶del, Escher, Bach: An Eternal Golden Braid - Douglas R. Hofstadter.](https://www.goodreads.com/book/show/24113.G_del_Escher_Bach) - This book is difficult to classify. [Hofstadter's Law](#hofstadters-law) is from the book.
- [The Dilbert Principle - Scott Adams](https://www.goodreads.com/book/show/85574.The_Dilbert_Principle) - A comic look at corporate America, from the author who created the [Dilbert Principle](#the-dilbert-principle).
- [The Peter Principle - Lawrence J. Peter](https://www.goodreads.com/book/show/890728.The_Peter_Principle) - Another comic look at the challenges of larger organisations and people management, the source of [The Peter Principle](#the-peter-principle).

## Contributing

Please do contribute! [Raise an issue](https://github.com/dwmkerr/hacker-laws/issues/new) if you'd like to suggest an addition or change, or [Open a pull request](https://github.com/dwmkerr/hacker-laws/compare) to propose your own changes.

Please be sure to read the [Contributing Guidelines](./.github/contributing.md) for requirements on text, style and so on. Please be aware of the [Code of Conduct](./.github/CODE_OF_CONDUCT.md) when engaging in discussions on the project.

## TODO

Hi! If you land here, you've clicked on a link to a topic I've not written up yet, sorry about this - this is work in progress!

Feel free to [Raise an Issue](https://github.com/dwmkerr/hacker-laws/issues) requesting more details, or [Open a Pull Request](https://github.com/dwmkerr/hacker-laws/pulls) to submit your proposed definition of the topic.
